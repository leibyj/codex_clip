#training
epochs: 10
learning_rate: 0.00005
weight_decay: 0.05
text_lr: 5e-5
codex_lr: 5e-4
he_lr: 5e-4
optimizer: "adam"
log_interval: 10
warmup_batches: 4000
amp: true 
gradient_clipping: false 
clip_value: 2.0


